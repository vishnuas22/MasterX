{
  "results": [
    {
      "provider": "groq",
      "model": "llama-3.3-70b-versatile",
      "message_type": "simple",
      "response_time_ms": 445.65296173095703,
      "success": true,
      "tokens_used": 89,
      "error": ""
    },
    {
      "provider": "groq",
      "model": "llama-3.3-70b-versatile",
      "message_type": "medium",
      "response_time_ms": 1329.9047946929932,
      "success": true,
      "tokens_used": 548,
      "error": ""
    },
    {
      "provider": "groq",
      "model": "llama-3.3-70b-versatile",
      "message_type": "complex",
      "response_time_ms": 12529.068946838379,
      "success": true,
      "tokens_used": 853,
      "error": ""
    },
    {
      "provider": "groq",
      "model": "llama-3.3-70b-versatile",
      "message_type": "emotional",
      "response_time_ms": 3412.1599197387695,
      "success": true,
      "tokens_used": 575,
      "error": ""
    },
    {
      "provider": "groq",
      "model": "llama-3.3-70b-versatile",
      "message_type": "analytical",
      "response_time_ms": 2246.0639476776123,
      "success": true,
      "tokens_used": 924,
      "error": ""
    },
    {
      "provider": "emergent",
      "model": "gpt-4o",
      "message_type": "simple",
      "response_time_ms": 839.2372131347656,
      "success": true,
      "tokens_used": 32.5,
      "error": ""
    },
    {
      "provider": "emergent",
      "model": "gpt-4o",
      "message_type": "medium",
      "response_time_ms": 6110.576391220093,
      "success": true,
      "tokens_used": 468.0,
      "error": ""
    },
    {
      "provider": "emergent",
      "model": "gpt-4o",
      "message_type": "complex",
      "response_time_ms": 7367.365837097168,
      "success": true,
      "tokens_used": 548.6,
      "error": ""
    },
    {
      "provider": "emergent",
      "model": "gpt-4o",
      "message_type": "emotional",
      "response_time_ms": 5849.826812744141,
      "success": true,
      "tokens_used": 422.5,
      "error": ""
    },
    {
      "provider": "emergent",
      "model": "gpt-4o",
      "message_type": "analytical",
      "response_time_ms": 10637.840509414673,
      "success": true,
      "tokens_used": 855.4,
      "error": ""
    },
    {
      "provider": "gemini",
      "model": "gemini-1.5-pro",
      "message_type": "simple",
      "response_time_ms": 139.54830169677734,
      "success": false,
      "tokens_used": 0,
      "error": "404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
    },
    {
      "provider": "gemini",
      "model": "gemini-1.5-pro",
      "message_type": "medium",
      "response_time_ms": 42.61469841003418,
      "success": false,
      "tokens_used": 0,
      "error": "404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
    },
    {
      "provider": "gemini",
      "model": "gemini-1.5-pro",
      "message_type": "complex",
      "response_time_ms": 39.345741271972656,
      "success": false,
      "tokens_used": 0,
      "error": "404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
    },
    {
      "provider": "gemini",
      "model": "gemini-1.5-pro",
      "message_type": "emotional",
      "response_time_ms": 29.686450958251953,
      "success": false,
      "tokens_used": 0,
      "error": "404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
    },
    {
      "provider": "gemini",
      "model": "gemini-1.5-pro",
      "message_type": "analytical",
      "response_time_ms": 31.344890594482422,
      "success": false,
      "tokens_used": 0,
      "error": "404 models/gemini-1.5-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
    }
  ],
  "analysis": {
    "provider_stats": {
      "groq": {
        "success_rate": 100.0,
        "avg_response_time_ms": 3992.570114135742,
        "min_response_time_ms": 445.65296173095703,
        "max_response_time_ms": 12529.068946838379,
        "total_tests": 5,
        "successful_tests": 5,
        "failed_tests": 0
      },
      "emergent": {
        "success_rate": 100.0,
        "avg_response_time_ms": 6160.969352722168,
        "min_response_time_ms": 839.2372131347656,
        "max_response_time_ms": 10637.840509414673,
        "total_tests": 5,
        "successful_tests": 5,
        "failed_tests": 0
      },
      "gemini": {
        "success_rate": 0,
        "avg_response_time_ms": 0,
        "min_response_time_ms": 0,
        "max_response_time_ms": 0,
        "total_tests": 5,
        "successful_tests": 0,
        "failed_tests": 5
      }
    },
    "overall_stats": {
      "total_tests": 15,
      "successful_tests": 10,
      "overall_success_rate": 66.66666666666666,
      "overall_avg_response_time_ms": 5076.769733428955,
      "overall_min_response_time_ms": 445.65296173095703,
      "overall_max_response_time_ms": 12529.068946838379
    }
  },
  "recommendations": {
    "conservative_timeout_ms": 25058,
    "balanced_timeout_ms": 18793,
    "aggressive_timeout_ms": 10153,
    "current_2s_timeout_success_rate": 30.0,
    "current_5s_timeout_success_rate": 50.0,
    "current_10s_timeout_success_rate": 80.0,
    "statistics": {
      "avg_response_time_ms": 5076.769733428955,
      "p95_response_time_ms": 12529.068946838379,
      "p99_response_time_ms": 12529.068946838379,
      "max_response_time_ms": 12529.068946838379
    }
  }
}